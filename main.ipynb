{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb7528c-1734-49fa-a8bf-50e3ed162993",
   "metadata": {},
   "source": [
    "## Main Notebook\n",
    "#### Use separate notebook when working to avoid merge conflicts!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8571517-eaae-408b-a40e-f0c9aff6601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pickle as pickle\n",
    "import csv as csv\n",
    "\n",
    "from sklearn import svm\n",
    "# import some validation tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from warnings import filterwarnings\n",
    "\n",
    "reg_class_file = \"/home/bwright1/scratch/weatherAUS_regression_and_classification_imputation.csv\"\n",
    "reg_mean_mode_file = \"/home/bwright1/scratch/weatherAUS_regression_and_mean_mode.csv\"\n",
    "just_mean_mode_file = \"/home/bwright1/scratch/weatherAUS_mean_mode_imputed.csv\"\n",
    "no_nans_file = \"/scratch/bwright1/weatherAUS_continous_normalized_no_nans.csv\"\n",
    "full_file = \"/scratch/bwright1/weatherAUS.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8922f-9c73-49e7-ba36-f2e5b2828564",
   "metadata": {},
   "source": [
    "## PipeLine Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062a3800-a66f-41cf-8b27-1119ee607352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(X):\n",
    "    \"\"\"\n",
    "    You will get overflow problems when calculating exponentials if \n",
    "    your feature values are too large.  This function adjusts all values to be\n",
    "    in the range of 0 to 1 for each column.\n",
    "    \"\"\"         \n",
    "    X = X - X.min() # shift range to start at 0\n",
    "    normalizedX = X/X.max() # divide by possible range of values so max is now 1\n",
    "    return normalizedX\n",
    "\n",
    "def normalize_data(X):\n",
    "    columns = X.columns\n",
    "    new = []\n",
    "    for column in columns:\n",
    "        # if column in ['WindGustDir', 'WindDir3pm', 'WindDir9am', 'RainToday']:\n",
    "        #     new.append(X[column])\n",
    "        #     continue\n",
    "        new.append(normalize_column(X[column]))\n",
    "    return pd.DataFrame(new).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b1d70a-26a5-45fc-8741-71e818ed3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_discrete_to_continous_column(column):\n",
    "    filterwarnings('ignore')\n",
    "    unique_values = column.unique()\n",
    "    print(unique_values)\n",
    "    num_uniques = len(unique_values)\n",
    "    print(len(column))\n",
    "    for i in range(num_uniques):\n",
    "        indices = np.where(column == unique_values[i])\n",
    "        column.loc[indices] = i\n",
    "\n",
    "def convert_discrete_to_continous_column_individualized(column, feature):\n",
    "    filterwarnings('ignore')\n",
    "    if (feature == 'WindGustDir') or (feature == 'WindDir3pm') or (feature == 'WindDir9am'):\n",
    "        directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
    "        value = 0\n",
    "        for direction in directions:\n",
    "            indices = np.where(column == direction)\n",
    "            column.loc[indices] = value\n",
    "            value += 1\n",
    "    elif (feature == 'RainToday'):\n",
    "        labels = ['No', 'Yes']\n",
    "        value = 0\n",
    "        for label in labels:\n",
    "            indices = np.where(column == label)\n",
    "            column.loc[indices] = value\n",
    "            value += 1\n",
    "    else:\n",
    "        raise KeyError(\"Invalid Key\")\n",
    "\n",
    "def convert_discrete_rain_columns(X, individualized=False):\n",
    "    discrete_columns = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
    "    #discrete_columns = ['WindGustDir']\n",
    "    for column in discrete_columns:\n",
    "        if individualized:\n",
    "            convert_discrete_to_continous_column_individualized(X[column], column)\n",
    "        else: \n",
    "            convert_discrete_to_continous_column(X[column])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdda9a3-206e-4e11-ae8e-231a06b18555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTuneTest_multithreaded(learner, parameters, X, y, continuous=False):\n",
    "    \"\"\"\n",
    "    Uses Stratified K Fold with 5 splits on an Exhaustive Grid Search to tune\n",
    "        hyperparameters on given learner. Finds best hyperparameters and score \n",
    "        for each fold\n",
    "    Params:\n",
    "        learner (SKLearn Model): The learner model to be evaluated\n",
    "        parameters (dict): The hyperparameters to tune\n",
    "        X (data): The feature values of the dataset to train/test on\n",
    "        y (data): The label values of the dataset to train/test on\n",
    "    Returns:\n",
    "        scores (list): A list of the best score for each fold\n",
    "    \"\"\"\n",
    "    splits = 5\n",
    "    #print(\"\\t In runTuneTest\")\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "    if continuous:\n",
    "        skf = RepeatedKFold(n_splits=3, n_repeats=2, random_state=0)\n",
    "    #print(len(skf.split(X,y)))\n",
    "    \n",
    "    scores = []\n",
    "    with ThreadPoolExecutor(max_workers=splits) as executor:\n",
    "        i=1\n",
    "        futures = []\n",
    "        for train, test in skf.split(X, y):\n",
    "            futures.append(executor.submit(__do_single_split, train, test, i, X, y, learner, parameters))\n",
    "            i+=1\n",
    "\n",
    "        for future in futures:\n",
    "            j, score, best_params = future.result()\n",
    "            scores.append(score)\n",
    "            print(f\"\\tFold {j}:\\n\\tBest parameters: {best_params}\\n\\tTuning Set Score: {score}\\n\")\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def runTuneTest_singlethread(learner, parameters, X, y, continuous=False):\n",
    "    \"\"\"\n",
    "    Uses Stratified K Fold with 5 splits on an Exhaustive Grid Search to tune\n",
    "        hyperparameters on given learner. Finds best hyperparameters and score \n",
    "        for each fold\n",
    "    Params:\n",
    "        learner (SKLearn Model): The learner model to be evaluated\n",
    "        parameters (dict): The hyperparameters to tune\n",
    "        X (data): The feature values of the dataset to train/test on\n",
    "        y (data): The label values of the dataset to train/test on\n",
    "    Returns:\n",
    "        scores (list): A list of the best score for each fold\n",
    "    \"\"\"\n",
    "    splits = 5\n",
    "    #print(\"\\t In runTuneTest\")\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "    if continuous:\n",
    "        skf = RepeatedKFold(n_splits=3, n_repeats=2, random_state=0)\n",
    "    #print(len(skf.split(X,y)))\n",
    "    \n",
    "    scores = []\n",
    "    models = []\n",
    "    i = 1\n",
    "    for train, test in skf.split(X, y):\n",
    "        j, score, best_params = __do_single_split(train, test, i, X, y, learner, parameters)\n",
    "        scores.append(score)\n",
    "        # models.append(model)\n",
    "        print(f\"\\tFold {i}:\\n\\tBest parameters: {best_params}\\n\\tTuning Set Score: {score['accuracy']}\\n\")\n",
    "        i+=1\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def __do_single_split(train, test, i, X, y, learner, parameters):\n",
    "    \"\"\"\n",
    "    Helper Function for RunTuneTest. Allows for easy parallelization of stratified folds\n",
    "    \"\"\"\n",
    "    print(f\"Executing fold {i}\")\n",
    "    clf = GridSearchCV(learner, parameters, cv=3)\n",
    "    #print(\"did_grid_search\")\n",
    "    trainX = X.iloc[train]\n",
    "    trainY = y.iloc[train]\n",
    "    clf.fit(trainX, trainY)\n",
    "    #print(\"did_fit\")\n",
    "    testX = X.iloc[test]\n",
    "    testY = y.iloc[test]\n",
    "    score = clf.score(testX, testY)\n",
    "    y_predicted = clf.predict(testX)\n",
    "    report = classification_report(testY, y_predicted, output_dict=True)\n",
    "    # print((report))\n",
    "    scores = {\"accuracy\": score, \"no_precision\": report['No']['precision'], \"no_recall\": report['No']['recall'], \"yes_precision\": report['Yes']['precision'], \"yes_recall\": report['Yes']['recall']}\n",
    "    best_params = clf.best_params_\n",
    "    return i, scores, best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676609bc-9eb2-4cd4-b998-bf2601cccd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns) throwing an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1b40b2-8424-4f4d-af4c-829dbd451247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPipeline(X, y, identifier=\"\"):\n",
    "    \"\"\"\n",
    "    PipeLine function that identifies the best parameters for each model.\n",
    "        Prints the accuracy scores for each model, across 5 Stratified K Folds. \n",
    "        Runs pipeline for a Random Forest, K Nearest Neighbors, Decision Tree, and Stochastic Gradient Descent Classifiers\n",
    "    Params:\n",
    "        X (pd.Dataframe) : Examples to train/test on\n",
    "        y (pd.Dataframe) : Example labels to train/test on\n",
    "        identifier (str) : Optional name of data\n",
    "    Returns:\n",
    "        dictionary of accuracy scores for each model\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Running pipeline for\", f\"'{identifier}'\")\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100)  # Fewer trees\n",
    "    rf_parameters = {\n",
    "        'n_estimators': [50, 100], #'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20], #'max_depth': [None, 10, 20, 50],\n",
    "        'min_samples_split': [2, 10, 50], #'min_samples_split': [2, 5, 10],\n",
    "        }\n",
    "    rf_results = runTuneTest_multithreaded(rf_classifier, rf_parameters, X, y)\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    knn_parameters = {\n",
    "        'n_neighbors': [5, 10, 20], #'n_neighbors': [3, 5, 10, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        }\n",
    "    knn_results = runTuneTest_multithreaded(knn_classifier, knn_parameters, X, y)\n",
    "\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    dt_parameters = {\n",
    "        'max_depth': [None, 10, 20], #'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 10, 50],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        }\n",
    "    dt_results = runTuneTest_multithreaded(dt_classifier, dt_parameters, X, y)\n",
    "\n",
    "    sgd_classifier = SGDClassifier(loss='log_loss', max_iter=50, tol=None, penalty=None, eta0=0.1)\n",
    "    sgd_parameters = {\n",
    "        'loss': ['hinge', 'log_loss'],\n",
    "        'penalty': ['l2', 'elasticnet'],\n",
    "        'alpha': [1e-4, 1e-2],\n",
    "        }\n",
    "    sgd_results = runTuneTest_multithreaded(sgd_classifier, sgd_parameters, X, y)\n",
    "\n",
    "    final_res = [rf_results, knn_results, dt_results, sgd_results] # , mlp_results]\n",
    "    classifiers = [\"RandomForest\", \"KNN\", \"DecisionTree\", \"SGD\"] # , \"MLP\"]\n",
    "\n",
    "    values = dict(zip(classifiers, final_res))\n",
    "\n",
    "    print(f\"Identifier: {identifier}\")\n",
    "    for name, results in zip(classifiers, final_res):\n",
    "        for fold, acc in enumerate(results, 1):\n",
    "            print(f\"{name}, Fold {fold}: {acc['accuracy'] * 100:.2f}%\")\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ca410e-750c-4aed-a541-c8c4748ff484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_runPipeline(data, identifier=\"\"):\n",
    "    return runPipeline(data.drop(columns=['RainTomorrow']), data['RainTomorrow'], identifier=identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4872f6a-9279-41a5-8e71-94e2667b057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e268b7c-be62-41da-a3f1-052882aac9c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m runPipeline(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRainTomorrow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRainTomorrow\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "scores = runPipeline(data.drop(columns=['RainTomorrow', 'Location', 'Date']), data['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd9314-e154-4539-b57e-99ab9adf2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684a2b5-e600-454e-b9ff-ae88acff37da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddab997c-cf31-45c2-8909-0b39a074b5d3",
   "metadata": {},
   "source": [
    "# Running pipeline on all .csv datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bddd7-139c-4762-9262-8e8a7e7d6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = ['remove', 'reg-class', 'mean-mode', 'hybrid']\n",
    "variations = ['drop-loc+date', 'drop-loc-(month-disc)', 'drop-loc-(month-circ)', 'drop-date-(lat-long)', \n",
    "              'disc-month-lat-long', 'disc-month+loc', 'month-circ-lat-long', 'month-circ-lat-long-wind-circ', \n",
    "              'split-loc-(drop-date)', 'split-season-(drop-loc)', 'split-loc+season',\n",
    "              'split-loc-(month-disc)', 'split-season-(month-circ)', 'split-season-(lat-long)',\n",
    "              'rm-temp1', 'rm-temp2', 'rm-temp3', 'rm-temp4', 'rm-temp5', 'rm-temp6', 'rm-pres1', 'rm-pres2', \n",
    "              'rm-hum1', 'rm-hum2', 'rm-1', 'rm-2', 'rm-3', 'rm-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519a670-53d4-437e-b42d-d030129bbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = \"hybrid\"\n",
    "var = \"split-season-(drop-loc)\"\n",
    "data = pd.read_csv(f'/scratch/srebarb1/NewCSVs/{imp}_{var}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab4e8a-52cc-4735-8c70-e5469a74efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = [\"hybrid\"]\n",
    "variations = [\"disc-month+loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482e744-f871-4894-bcb4-5a391e9ab2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba9d442-2b22-46d4-8007-5b7550ae510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(imputations, variations):\n",
    "    start = time.time()\n",
    "    dictionary = {}\n",
    "    for imp in imputations:\n",
    "        dictionary[imp] = {}\n",
    "        for var in variations:\n",
    "            data = pd.read_csv(f'/scratch/srebarb1/NewCSVs/{imp}_{var}.csv')\n",
    "            display(data)\n",
    "            if 'split-loc' in var:\n",
    "                new_dict = {}\n",
    "                locs = data.Location.unique()\n",
    "                for loc in locs:\n",
    "                    new_data = data[data.Location == loc]\n",
    "                    new_dict[loc] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{loc}')\n",
    "            elif 'split-season' in var:\n",
    "                new_dict = {}\n",
    "                seasons = data.Season.unique()\n",
    "                for season in seasons:\n",
    "                    new_data = data[data.Season == season]\n",
    "                    new_dict[season] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{season}')\n",
    "            elif 'split-loc+season' in var:\n",
    "                new_dict = {}\n",
    "                locs = data.Location.unique()\n",
    "                seasons = data.Season.unique()\n",
    "                for loc in locs:\n",
    "                    new_dict[loc] = {}\n",
    "                    for season in seasons:\n",
    "                        new_data = data[(data.Location == loc) and (data.Season == season)]\n",
    "                        new_dict[loc][season] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{loc}_{season}')\n",
    "            else:\n",
    "                new_dict = new_runPipeline(data, identifier=f'{imp}_{var}')\n",
    "    \n",
    "            with open(f'/scratch/srebarb1/MLproject_dictionaries/{imp}_{var}.pkl', \"wb\") as f:\n",
    "                pickle.dump(new_dict, f)\n",
    "            dictionary[imp][var] = new_dict\n",
    "    \n",
    "    #with open(f'/scratch/srebarb1/MLproject_dictionaries/all.pkl', \"wb\") as f:\n",
    "    #    pickle.dump(dictionary, f)\n",
    "    #end = time.time()\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91863e5-95b7-4ef8-9e34-04dd1794ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dictionary = {}\n",
    "for imp in imputations:\n",
    "    dictionary[imp] = {}\n",
    "    for var in variations:\n",
    "        data = pd.read_csv(f'/scratch/srebarb1/NewCSVs/{imp}_{var}.csv')\n",
    "        display(data)\n",
    "        if 'split-loc' in var:\n",
    "            new_dict = {}\n",
    "            locs = data.Location.unique()\n",
    "            for loc in locs:\n",
    "                new_data = data[data.Location == loc]\n",
    "                new_dict[loc] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{loc}')\n",
    "        elif 'split-season' in var:\n",
    "            new_dict = {}\n",
    "            seasons = data.Season.unique()\n",
    "            for season in seasons:\n",
    "                new_data = data[data.Season == season]\n",
    "                new_dict[season] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{season}')\n",
    "        elif 'split-loc+season' in var:\n",
    "            new_dict = {}\n",
    "            locs = data.Location.unique()\n",
    "            seasons = data.Season.unique()\n",
    "            for loc in locs:\n",
    "                new_dict[loc] = {}\n",
    "                for season in seasons:\n",
    "                    new_data = data[(data.Location == loc) and (data.Season == season)]\n",
    "                    new_dict[loc][season] = new_runPipeline(new_data, identifier=f'{imp}_{var}_{loc}_{season}')\n",
    "        else:\n",
    "            new_dict = new_runPipeline(data, identifier=f'{imp}_{var}')\n",
    "\n",
    "        with open(f'/scratch/srebarb1/MLproject_dictionaries/{imp}_{var}.pkl', \"wb\") as f:\n",
    "            pickle.dump(new_dict, f)\n",
    "        dictionary[imp][var] = new_dict\n",
    "\n",
    "with open(f'/scratch/srebarb1/MLproject_dictionaries/all.pkl', \"wb\") as f:\n",
    "    pickle.dump(dictionary, f)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d287f3a-b721-4e7c-8a7b-e5320476a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/scratch/srebarb1/MLproject_dictionaries/{imp}_{var}.pkl', 'rb') as file:\n",
    "    practice = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42b3ec-1c68-4264-97bb-06392370f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/scratch/srebarb1/MLproject_dictionaries/{imp}_{var}.pkl', \"wb\") as f:\n",
    "    pickle.dump(new_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03175fc-0ab5-441b-bb77-2a9ef62730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice['KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79a66d-2268-469e-9fec-9939bf159a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[imp][var] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59980ab-4433-4c62-a906-26c8b8a80cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict[0.0]['RandomForest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20004b9-d958-47a2-97dc-826a03dfd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['hybrid']['split-season'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb59d-bf2a-4ba3-b937-d8743cd77890",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286715b3-0751-40f6-8016-2fb87f3edc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/srebarb1/MLproject_dictionaries/hybrid_rm-all-but-rain+temp.pkl', 'rb') as file:\n",
    "    practice = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5417cac2-fc3e-44ac-a96f-fa302faa974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/scratch/srebarb1/NewNewCSVs/reg-class_disc-month-lat-long.csv\"\n",
    "test = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec6ed9d-306c-49e8-a461-2024501f1da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Month</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516509</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.063141</td>\n",
       "      <td>0.596345</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.294574</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.449587</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.508439</td>\n",
       "      <td>0.522073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>-36.0802</td>\n",
       "      <td>146.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073556</td>\n",
       "      <td>0.795448</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.294574</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.497521</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.570058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>-36.0802</td>\n",
       "      <td>146.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.504717</td>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095832</td>\n",
       "      <td>0.806069</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.447934</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.548944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>-36.0802</td>\n",
       "      <td>146.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417453</td>\n",
       "      <td>0.620038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076483</td>\n",
       "      <td>0.780690</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.613223</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.533755</td>\n",
       "      <td>0.612284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>-36.0802</td>\n",
       "      <td>146.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.701323</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.081881</td>\n",
       "      <td>0.553655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.500826</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.527426</td>\n",
       "      <td>0.673704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>-36.0802</td>\n",
       "      <td>146.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142188</th>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.502836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062265</td>\n",
       "      <td>0.796828</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.730579</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>0.350211</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>-25.3444</td>\n",
       "      <td>131.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142189</th>\n",
       "      <td>0.266509</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.783379</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.728926</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.364979</td>\n",
       "      <td>0.533589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>-25.3444</td>\n",
       "      <td>131.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142190</th>\n",
       "      <td>0.285377</td>\n",
       "      <td>0.568998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070554</td>\n",
       "      <td>0.796690</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.381857</td>\n",
       "      <td>0.573896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>-25.3444</td>\n",
       "      <td>131.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142191</th>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073861</td>\n",
       "      <td>0.820138</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.240310</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.415612</td>\n",
       "      <td>0.604607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>-25.3444</td>\n",
       "      <td>131.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142192</th>\n",
       "      <td>0.384434</td>\n",
       "      <td>0.601134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075092</td>\n",
       "      <td>0.791862</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.642975</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.470464</td>\n",
       "      <td>0.602687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>-25.3444</td>\n",
       "      <td>131.0369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142193 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
       "0       0.516509  0.523629  0.001617     0.063141  0.596345     0.666667   \n",
       "1       0.375000  0.565217  0.000000     0.073556  0.795448     0.200000   \n",
       "2       0.504717  0.576560  0.000000     0.095832  0.806069     0.733333   \n",
       "3       0.417453  0.620038  0.000000     0.076483  0.780690     0.466667   \n",
       "4       0.613208  0.701323  0.002695     0.081881  0.553655     0.666667   \n",
       "...          ...       ...       ...          ...       ...          ...   \n",
       "142188  0.283019  0.502836  0.000000     0.062265  0.796828     0.533333   \n",
       "142189  0.266509  0.533081  0.000000     0.066053  0.783379     0.533333   \n",
       "142190  0.285377  0.568998  0.000000     0.070554  0.796690     0.800000   \n",
       "142191  0.327830  0.599244  0.000000     0.073861  0.820138     0.266667   \n",
       "142192  0.384434  0.601134  0.000000     0.075092  0.791862     0.333333   \n",
       "\n",
       "        WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
       "0            0.294574    0.666667    0.200000      0.153846  ...         0.22   \n",
       "1            0.294574    0.800000    0.733333      0.030769  ...         0.25   \n",
       "2            0.310078    0.666667    0.733333      0.146154  ...         0.30   \n",
       "3            0.139535    0.333333    0.533333      0.084615  ...         0.16   \n",
       "4            0.271318    0.400000    1.000000      0.053846  ...         0.33   \n",
       "...               ...         ...         ...           ...  ...          ...   \n",
       "142188       0.193798    0.866667    0.533333      0.115385  ...         0.27   \n",
       "142189       0.193798    0.333333    0.400000      0.100000  ...         0.24   \n",
       "142190       0.124031    0.333333    0.266667      0.100000  ...         0.21   \n",
       "142191       0.240310    0.333333    0.200000      0.069231  ...         0.24   \n",
       "142192       0.170543    0.933333    0.266667      0.100000  ...         0.24   \n",
       "\n",
       "        Pressure9am  Pressure3pm   Temp9am   Temp3pm  RainToday  RainTomorrow  \\\n",
       "0          0.449587       0.4800  0.508439  0.522073        0.0            No   \n",
       "1          0.497521       0.4912  0.514768  0.570058        0.0            No   \n",
       "2          0.447934       0.5056  0.594937  0.548944        0.0            No   \n",
       "3          0.613223       0.5712  0.533755  0.612284        0.0            No   \n",
       "4          0.500826       0.4624  0.527426  0.673704        0.0            No   \n",
       "...             ...          ...       ...       ...        ...           ...   \n",
       "142188     0.730579       0.7056  0.350211  0.504798        0.0            No   \n",
       "142189     0.728926       0.6912  0.364979  0.533589        0.0            No   \n",
       "142190     0.710744       0.6720  0.381857  0.573896        0.0            No   \n",
       "142191     0.669421       0.6352  0.415612  0.604607        0.0            No   \n",
       "142192     0.642975       0.6304  0.470464  0.602687        0.0            No   \n",
       "\n",
       "        Month Latitude  Longitude  \n",
       "0          12 -36.0802   146.9137  \n",
       "1          12 -36.0802   146.9137  \n",
       "2          12 -36.0802   146.9137  \n",
       "3          12 -36.0802   146.9137  \n",
       "4          12 -36.0802   146.9137  \n",
       "...       ...      ...        ...  \n",
       "142188      6 -25.3444   131.0369  \n",
       "142189      6 -25.3444   131.0369  \n",
       "142190      6 -25.3444   131.0369  \n",
       "142191      6 -25.3444   131.0369  \n",
       "142192      6 -25.3444   131.0369  \n",
       "\n",
       "[142193 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6ab42c-01f9-48cd-b911-66f68f4ebe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForest': [{'accuracy': 0.799008403952319,\n",
       "   'no_precision': 0.8161844344731549,\n",
       "   'no_recall': 0.956308919506889,\n",
       "   'yes_precision': 0.6273676072671047,\n",
       "   'yes_recall': 0.25458823529411767},\n",
       "  {'accuracy': 0.8006962270122016,\n",
       "   'no_precision': 0.817942054842338,\n",
       "   'no_recall': 0.955853691701038,\n",
       "   'yes_precision': 0.6332831325301205,\n",
       "   'yes_recall': 0.263801756587202},\n",
       "  {'accuracy': 0.7991138928935616,\n",
       "   'no_precision': 0.8170079106561191,\n",
       "   'no_recall': 0.9549471966640982,\n",
       "   'yes_precision': 0.6250471520181063,\n",
       "   'yes_recall': 0.25988080301129235},\n",
       "  {'accuracy': 0.8000210985301357,\n",
       "   'no_precision': 0.8180546923555003,\n",
       "   'no_recall': 0.9545392738974754,\n",
       "   'yes_precision': 0.6276911655530809,\n",
       "   'yes_recall': 0.26525490196078433},\n",
       "  {'accuracy': 0.8007947113017793,\n",
       "   'no_precision': 0.818630498989585,\n",
       "   'no_recall': 0.9547658976567104,\n",
       "   'yes_precision': 0.631189948263119,\n",
       "   'yes_recall': 0.267921568627451}],\n",
       " 'KNN': [{'accuracy': 0.7932065121839728,\n",
       "   'no_precision': 0.8133689632469695,\n",
       "   'no_recall': 0.9518672951414068,\n",
       "   'yes_precision': 0.5943468296409473,\n",
       "   'yes_recall': 0.24407843137254903},\n",
       "  {'accuracy': 0.7957030837933823,\n",
       "   'no_precision': 0.8154574744769225,\n",
       "   'no_recall': 0.9521370620495853,\n",
       "   'yes_precision': 0.6056758775205378,\n",
       "   'yes_recall': 0.25439146800501883},\n",
       "  {'accuracy': 0.7944020535180562,\n",
       "   'no_precision': 0.814678258169681,\n",
       "   'no_recall': 0.9514118660200336,\n",
       "   'yes_precision': 0.5989524878413768,\n",
       "   'yes_recall': 0.2510978670012547},\n",
       "  {'accuracy': 0.7952739292495956,\n",
       "   'no_precision': 0.8153714707367277,\n",
       "   'no_recall': 0.9515931650274215,\n",
       "   'yes_precision': 0.602826329490517,\n",
       "   'yes_recall': 0.2542745098039216},\n",
       "  {'accuracy': 0.7960123778043463,\n",
       "   'no_precision': 0.8158651231450548,\n",
       "   'no_recall': 0.9519104382903504,\n",
       "   'yes_precision': 0.6064540059347181,\n",
       "   'yes_recall': 0.2564705882352941}],\n",
       " 'DecisionTree': [{'accuracy': 0.7963360174408383,\n",
       "   'no_precision': 0.8169458511881574,\n",
       "   'no_recall': 0.950462291515591,\n",
       "   'yes_precision': 0.6052726616106898,\n",
       "   'yes_recall': 0.2629019607843137},\n",
       "  {'accuracy': 0.7980941664615493,\n",
       "   'no_precision': 0.8182349959053153,\n",
       "   'no_recall': 0.9510039432534106,\n",
       "   'yes_precision': 0.6133762517882689,\n",
       "   'yes_recall': 0.26897741530740277},\n",
       "  {'accuracy': 0.7952811280284117,\n",
       "   'no_precision': 0.8181889424395595,\n",
       "   'no_recall': 0.9464261433168654,\n",
       "   'yes_precision': 0.594928032899246,\n",
       "   'yes_recall': 0.2722710163111669},\n",
       "  {'accuracy': 0.7966453337084183,\n",
       "   'no_precision': 0.8170028818443804,\n",
       "   'no_recall': 0.9508679689978697,\n",
       "   'yes_precision': 0.6072463768115942,\n",
       "   'yes_recall': 0.2629019607843137},\n",
       "  {'accuracy': 0.7997397847949926,\n",
       "   'no_precision': 0.819114091866178,\n",
       "   'no_recall': 0.9521370620495853,\n",
       "   'yes_precision': 0.6217765042979942,\n",
       "   'yes_recall': 0.27231372549019606}],\n",
       " 'SGD': [{'accuracy': 0.7968634621470516,\n",
       "   'no_precision': 0.8201438848920863,\n",
       "   'no_recall': 0.9455221174764322,\n",
       "   'yes_precision': 0.5996002664890073,\n",
       "   'yes_recall': 0.2823529411764706},\n",
       "  {'accuracy': 0.7980238405007208,\n",
       "   'no_precision': 0.8184692244643066,\n",
       "   'no_recall': 0.9504600462312469,\n",
       "   'yes_precision': 0.6121362668559261,\n",
       "   'yes_recall': 0.27054579673776663},\n",
       "  {'accuracy': 0.7965821583037378,\n",
       "   'no_precision': 0.8128699930806489,\n",
       "   'no_recall': 0.958437202556316,\n",
       "   'yes_precision': 0.6218556701030927,\n",
       "   'yes_recall': 0.23651191969887075},\n",
       "  {'accuracy': 0.7980870666010268,\n",
       "   'no_precision': 0.8115527049211622,\n",
       "   'no_recall': 0.9634682500113312,\n",
       "   'yes_precision': 0.6409799554565702,\n",
       "   'yes_recall': 0.22572549019607843},\n",
       "  {'accuracy': 0.7979815739503481,\n",
       "   'no_precision': 0.8179657053780203,\n",
       "   'no_recall': 0.9513212165163396,\n",
       "   'yes_precision': 0.6133909287257019,\n",
       "   'yes_recall': 0.26729411764705885}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90d3e93-481a-4781-a6ca-aec1e49a7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "imp = 'remove'\n",
    "var = 'disc-month-lat-long'\n",
    "with open(f'/scratch/srebarb1/MLproject_dictionaries/{imp}_{var}.pkl', 'rb') as file:\n",
    "    practice = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfbf5ff-f190-488e-8cdf-f4b27f3a7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RandomForest', 'KNN', 'DecisionTree', 'SGD'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9662aa40-3fdd-4d19-908c-c3e92eb4143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/scratch/srebarb1/MLproject_dictionaries/all.pkl', 'rb') as file:\n",
    "    all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27998a7-685a-4d37-b48c-4108c6c0ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /scratch/srebarb1/MLproject_dictionaries/all.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9834c5e3-e923-498d-bb6f-21fa2374b6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['disc-month+loc'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all['hybrid'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a712c1e-20ea-41fc-8e12-dfaf41bc01ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dictionaries: ['reg-class_split-season-(lat-long).pkl', 'hybrid_rm-pres1.pkl', 'mean-mode_month-circ-lat-long-wind-circ.pkl', 'hybrid_split-season-(lat-long).pkl', 'mean-mode_rm-hum1.pkl', 'hybrid_rm-rain.pkl', 'remove_rm-4.pkl', 'reg-class_rm-rain.pkl', 'hybrid_split-loc-(month-circ).pkl', 'reg-class_rm-pres2.pkl', 'reg-class_split-loc-(month-circ).pkl', 'remove_split-loc+season.pkl', 'mean-mode_disc-month+loc.pkl', 'reg-class_rm-4.pkl', 'mean-mode_rm-3.pkl', 'mean-mode_rm-temp2.pkl', 'hybrid_rm-4.pkl', 'reg-class_split-season-(drop-loc).pkl', 'hybrid_disc-month-lat-long.pkl', 'hybrid_rm-1.pkl', 'reg-class_rm-1.pkl', 'hybrid_split-loc-(drop-date).pkl', 'reg-class_month-circ-lat-long-wind-circ.pkl', 'mean-mode_rm-all-but-rain+temp.pkl', 'remove_rm-hum2.pkl', 'hybrid_rm-all-but-rain+temp.pkl', 'remove_rm-all-but-rain.pkl', 'reg-class_split-loc+season.pkl', 'remove_month-circ-lat-long.pkl', 'hybrid_month-circ-lat-long-wind-circ.pkl', 'mean-mode_rm-pres2.pkl', 'hybrid_drop-loc+date.pkl', 'hybrid_month-circ-lat-long.pkl', 'remove_split-loc-(drop-date).pkl', 'remove_rm-pres2.pkl', 'mean-mode_rm-temp1.pkl', 'remove_rm-temp2.pkl', 'remove_drop-loc-(month-disc).pkl', 'hybrid_disc-month+loc.pkl', 'mean-mode_split-loc-(month-disc).pkl', 'remove_rm-hum1.pkl', 'reg-class_month-circ-lat-long.pkl', 'remove_drop-date-(lat-long).pkl', 'reg-class_rm-hum2.pkl', 'remove_drop-loc+date.pkl', 'remove_rm-all-but-rain+temp.pkl', 'reg-class_drop-loc+date.pkl', 'reg-class_rm-2.pkl', 'mean-mode_split-season-(drop-loc).pkl', 'mean-mode_disc-month-lat-long.pkl', 'mean-mode_rm-rain.pkl', 'hybrid_rm-temp2.pkl', 'mean-mode_drop-loc-(month-circ).pkl', 'remove_month-circ-lat-long-wind-circ.pkl', 'remove_rm-1.pkl', 'reg-class_rm-temp2.pkl', 'reg-class_split-loc-(drop-date).pkl', 'reg-class_rm-all-but-rain.pkl', 'hybrid_split-season-(drop-loc).pkl', 'reg-class_drop-date-(lat-long).pkl', 'remove_rm-temp1.pkl', 'reg-class_drop-loc-(month-circ).pkl', 'hybrid_rm-all-but-rain.pkl', 'remove_disc-month-lat-long.pkl', 'mean-mode_split-loc+season.pkl', 'reg-class_split-loc-(month-disc).pkl', 'mean-mode_rm-pres1.pkl', 'hybrid_split-loc+season.pkl', 'remove_rm-3.pkl', 'mean-mode_split-loc-(month-circ).pkl', 'remove_rm-pres1.pkl', 'remove_split-season-(drop-loc).pkl', 'hybrid_rm-2.pkl', 'mean-mode_drop-date-(lat-long).pkl', 'remove_rm-2.pkl', 'hybrid_rm-hum2.pkl', 'remove_disc-month+loc.pkl', 'reg-class_rm-temp1.pkl', 'mean-mode_rm-hum2.pkl', 'remove_split-loc-(month-circ).pkl', 'hybrid_rm-hum1.pkl', 'mean-mode_drop-loc+date.pkl', 'reg-class_rm-3.pkl', 'hybrid_rm-3.pkl', 'reg-class_disc-month+loc.pkl', 'hybrid_drop-date-(lat-long).pkl', 'hybrid_split-loc-(month-disc).pkl', 'reg-class_disc-month-lat-long.pkl', 'remove_split-season-(lat-long).pkl', 'mean-mode_rm-all-but-rain.pkl', 'reg-class_drop-loc-(month-disc).pkl', 'mean-mode_month-circ-lat-long.pkl', 'mean-mode_rm-1.pkl', 'reg-class_rm-all-but-rain+temp.pkl', 'reg-class_rm-hum1.pkl', 'hybrid_rm-pres2.pkl', 'reg-class_rm-pres1.pkl', 'mean-mode_rm-4.pkl', 'mean-mode_split-season-(lat-long).pkl', 'hybrid_drop-loc-(month-disc).pkl', 'hybrid_drop-loc-(month-circ).pkl', 'remove_drop-loc-(month-circ).pkl', 'mean-mode_split-loc-(drop-date).pkl', 'mean-mode_rm-2.pkl', 'hybrid_rm-temp1.pkl', 'remove_rm-rain.pkl', 'mean-mode_drop-loc-(month-disc).pkl', 'remove_split-loc-(month-disc).pkl']\n",
      "--------------------\n",
      "{'RandomForest': [{'accuracy': 0.8501002144941805, 'no_precision': 0.8622064867944492, 'no_recall': 0.9602519941986947, 'yes_precision': 0.773150543197103, 'yes_recall': 0.4688627450980392}, {'accuracy': 0.8514364077499209, 'no_precision': 0.8631514657980456, 'no_recall': 0.9608394144042062, 'yes_precision': 0.777262180974478, 'yes_recall': 0.47286700125470515}, {'accuracy': 0.8521748303386195, 'no_precision': 0.8622662176964583, 'no_recall': 0.9633322757557903, 'yes_precision': 0.7865435356200527, 'yes_recall': 0.467534504391468}, {'accuracy': 0.8485828820592165, 'no_precision': 0.8595553395699186, 'no_recall': 0.9620178579522277, 'yes_precision': 0.7762349799732977, 'yes_recall': 0.456}, {'accuracy': 0.8526619312187917, 'no_precision': 0.8645319192331226, 'no_recall': 0.9606127906449712, 'yes_precision': 0.7784858526637777, 'yes_recall': 0.47905882352941176}], 'KNN': [{'accuracy': 0.8415907732339393, 'no_precision': 0.8556901511161528, 'no_recall': 0.9572606961566352, 'yes_precision': 0.7489350372736954, 'yes_recall': 0.4412549019607843}, {'accuracy': 0.8427159886071943, 'no_precision': 0.8569689098141083, 'no_recall': 0.9569868104972126, 'yes_precision': 0.7503288608260984, 'yes_recall': 0.4473023839397742}, {'accuracy': 0.8403249059390274, 'no_precision': 0.8495172743955957, 'no_recall': 0.9651452658296695, 'yes_precision': 0.7720130447672695, 'yes_recall': 0.4084065244667503}, {'accuracy': 0.8411983965117097, 'no_precision': 0.8550443122496054, 'no_recall': 0.9576666817749173, 'yes_precision': 0.7493962972900456, 'yes_recall': 0.43811764705882356}, {'accuracy': 0.841092903861031, 'no_precision': 0.8509080726458117, 'no_recall': 0.964102796537189, 'yes_precision': 0.7697674418604651, 'yes_recall': 0.41537254901960785}], 'DecisionTree': [{'accuracy': 0.841379795351454, 'no_precision': 0.8634011014036685, 'no_recall': 0.9450688905003626, 'yes_precision': 0.7173507462686567, 'yes_recall': 0.4825098039215686}, {'accuracy': 0.8410984915081402, 'no_precision': 0.8621501114689125, 'no_recall': 0.9465167928205593, 'yes_precision': 0.72018022290728, 'yes_recall': 0.47631744040150564}, {'accuracy': 0.8410984915081402, 'no_precision': 0.863681592039801, 'no_recall': 0.9442052304763632, 'yes_precision': 0.714980319518407, 'yes_recall': 0.48431618569636137}, {'accuracy': 0.8383852591602785, 'no_precision': 0.8609033431133518, 'no_recall': 0.9442505552282101, 'yes_precision': 0.7098372257607927, 'yes_recall': 0.472}, {'accuracy': 0.8395456783177438, 'no_precision': 0.8679872150727563, 'no_recall': 0.9354575533698953, 'yes_precision': 0.6944206008583691, 'yes_recall': 0.5076078431372549}], 'SGD': [{'accuracy': 0.8421533809205668, 'no_precision': 0.865308667636666, 'no_recall': 0.943391950688905, 'yes_precision': 0.7151003649635036, 'yes_recall': 0.49176470588235294}, {'accuracy': 0.8446499525299764, 'no_precision': 0.8594125555057645, 'no_recall': 0.9561709649639668, 'yes_precision': 0.7515416238437821, 'yes_recall': 0.4587515683814304}, {'accuracy': 0.8429621294700939, 'no_precision': 0.8586393836872783, 'no_recall': 0.9547658976567104, 'yes_precision': 0.7444956477214542, 'yes_recall': 0.4560853199498118}, {'accuracy': 0.8400379773542443, 'no_precision': 0.8520260492040521, 'no_recall': 0.9606581153968182, 'yes_precision': 0.7563166760247052, 'yes_recall': 0.42258823529411765}, {'accuracy': 0.8413742175961741, 'no_precision': 0.8608552631578947, 'no_recall': 0.9489190046684495, 'yes_precision': 0.7263234579893152, 'yes_recall': 0.4691764705882353}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "directory = \"./PklDicts\"\n",
    "\n",
    "files = os.listdir(directory)\n",
    "dictionaries = {}\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".pkl\"):  \n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            dictionaries[file] = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded dictionaries: {list(dictionaries.keys())}\")\n",
    "print(\"--------------------\")\n",
    "\n",
    "example_dict = dictionaries[\"hybrid_rm-1.pkl\"] \n",
    "print(example_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eecd0eb-6fb7-456e-9dab-d1b9661a79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickled_dictionaries(directory):\n",
    "    files = os.listdir(directory)\n",
    "    data_by_imp_var = {}\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "    \n",
    "            base_name = file[:-4] \n",
    "            parts = base_name.split('_', 1) \n",
    "            if len(parts) == 2:\n",
    "                imp, var = parts\n",
    "            else:\n",
    "                raise ValueError(f\"Filename {file} does not follow expected pattern.\")\n",
    "\n",
    "            if imp not in data_by_imp_var:\n",
    "                data_by_imp_var[imp] = {}\n",
    "            data_by_imp_var[imp][var] = data\n",
    "\n",
    "    return data_by_imp_var\n",
    "\n",
    "def run_friedman_test(loaded_data, imp, var, model='RandomForest', metric='accuracy'):\n",
    "    grouped_data = []\n",
    "\n",
    "    for method in imp:\n",
    "        if method not in loaded_data:\n",
    "            print(f\"Warning: '{method}' is missing in loaded_data.\")\n",
    "            continue\n",
    "        for variation in var:\n",
    "            if variation not in loaded_data[method]:\n",
    "                print(f\"Warning: '{variation}' is missing for '{method}' in loaded_data.\")\n",
    "                continue\n",
    "            \n",
    "            model_data = loaded_data[method][variation].get(model, [])\n",
    "\n",
    "            metric_values = [fold_result[metric] for fold_result in model_data if metric in fold_result]\n",
    "\n",
    "            if not metric_values:\n",
    "                print(f\"No metric values found for {method} - {variation} - {model}\")\n",
    "                continue\n",
    "            \n",
    "            grouped_data.append(metric_values)\n",
    "\n",
    "    group_lengths = [len(group) for group in grouped_data]\n",
    "    if len(set(group_lengths)) != 1:\n",
    "        print(f\"Group lengths: {group_lengths}\")\n",
    "        raise ValueError(\"All groups must have the same number of observations.\")\n",
    "    \n",
    "    from scipy.stats import friedmanchisquare\n",
    "    stat, p_value = friedmanchisquare(*grouped_data)\n",
    "    print(f\"Friedman test statistic: {stat}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "    \n",
    "    return stat, p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb9cb67-f7da-4f7e-8ee3-6fc22e69e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./PklDicts\"\n",
    "imp_methods = ['reg-class', 'mean-mode', 'hybrid']\n",
    "var_methods = ['drop-loc+date', 'drop-loc-(month-disc)', 'drop-loc-(month-circ)']\n",
    "\n",
    "loaded_data = load_pickled_dictionaries(directory)\n",
    "\n",
    "#stat, p_value = run_friedman_test(loaded_data, imp_methods, var_methods)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5ef575-f26b-495e-8a97-e687a59341d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RandomForest', 'KNN', 'DecisionTree', 'SGD'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['hybrid']['drop-loc+date'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcdcd872-6571-4638-9b79-73ab0dfc6be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in loaded_data: dict_keys(['reg-class', 'hybrid', 'mean-mode', 'remove'])\n",
      "'reg-class' exists in loaded_data.\n",
      "'mean-mode' exists in loaded_data.\n",
      "'hybrid' exists in loaded_data.\n",
      "Loaded file keys: dict_keys(['reg-class', 'hybrid', 'mean-mode', 'remove'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Top-level keys in loaded_data:\", loaded_data.keys())\n",
    "\n",
    "for imp in imp_methods:\n",
    "    if imp in loaded_data:\n",
    "        print(f\"'{imp}' exists in loaded_data.\")\n",
    "    else:\n",
    "        print(f\"Warning: '{imp}' is missing in loaded_data.\")\n",
    "\n",
    "print(\"Loaded file keys:\", loaded_data.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128913f-f508-4a80-8f5c-c0364bc8f9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
